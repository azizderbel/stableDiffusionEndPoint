{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KV8d1zfuN8Ur",
        "outputId": "7a3d4392-4683-4bf3-b590-19bf9c3cf138"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'stableDiffusionEndPoint'...\n",
            "remote: Enumerating objects: 47, done.\u001b[K\n",
            "remote: Counting objects: 100% (47/47), done.\u001b[K\n",
            "remote: Compressing objects: 100% (33/33), done.\u001b[K\n",
            "remote: Total 47 (delta 17), reused 39 (delta 9), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (47/47), 124.50 KiB | 1.60 MiB/s, done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/azizderbel/stableDiffusionEndPoint.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "20FAckIsN8Uu"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir(\"stableDiffusionEndPoint\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uxY0OuemN8Uv"
      },
      "outputs": [],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o6E0M8rNN8Uw"
      },
      "outputs": [],
      "source": [
        "!ngrok authtoken <>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yH5NpXTnN8Uw",
        "outputId": "e57ec5e0-9b66-4406-890f-678f3f17d518"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-03-02 13:44:16.525332: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-03-02 13:44:17.442282: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-02 13:44:17.442387: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-02 13:44:17.442405: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Downloading (…)p16/model_index.json: 100% 543/543 [00:00<00:00, 66.5kB/s]\n",
            "Fetching 15 files:   0% 0/15 [00:00<?, ?it/s]\n",
            "Downloading (…)\"pytorch_model.bin\";:   0% 0.00/608M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "Downloading (…)\"pytorch_model.bin\";:   0% 0.00/246M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)rocessor_config.json: 100% 342/342 [00:00<00:00, 40.2kB/s]\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)_encoder/config.json: 100% 636/636 [00:00<00:00, 54.3kB/s]\n",
            "Fetching 15 files:   7% 1/15 [00:00<00:05,  2.56it/s]\n",
            "\n",
            "\n",
            "Downloading (…)_checker/config.json:   0% 0.00/4.70k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)cheduler_config.json:   0% 0.00/307 [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)tokenizer/merges.txt:   0% 0.00/525k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)cheduler_config.json: 100% 307/307 [00:00<00:00, 8.61kB/s]\n",
            "Downloading (…)_checker/config.json: 100% 4.70k/4.70k [00:00<00:00, 103kB/s]\n",
            "Downloading (…)cial_tokens_map.json: 100% 472/472 [00:00<00:00, 20.1kB/s]\n",
            "\n",
            "Downloading (…)\"pytorch_model.bin\";:   2% 10.5M/608M [00:00<00:09, 59.9MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)\"pytorch_model.bin\";:   4% 10.5M/246M [00:00<00:03, 61.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)tokenizer/merges.txt: 100% 525k/525k [00:00<00:00, 3.31MB/s]\n",
            "\n",
            "Downloading (…)\"pytorch_model.bin\";:   3% 21.0M/608M [00:00<00:08, 70.3MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)\"pytorch_model.bin\";:   9% 21.0M/246M [00:00<00:03, 68.0MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)\"pytorch_model.bin\";:   5% 31.5M/608M [00:00<00:08, 69.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)okenizer_config.json: 100% 822/822 [00:00<00:00, 273kB/s]\n",
            "\n",
            "\n",
            "Downloading (…)\"pytorch_model.bin\";:  13% 31.5M/246M [00:00<00:03, 61.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:   0% 0.00/1.72G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)tokenizer/vocab.json:   0% 0.00/1.06M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)9cc2/vae/config.json:   0% 0.00/609 [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)cc2/unet/config.json: 100% 806/806 [00:00<00:00, 265kB/s]\n",
            "Downloading (…)9cc2/vae/config.json: 100% 609/609 [00:00<00:00, 55.2kB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:   0% 0.00/167M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)\"pytorch_model.bin\";:   9% 52.4M/608M [00:00<00:05, 94.7MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)\"pytorch_model.bin\";:  17% 41.9M/246M [00:00<00:02, 68.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:   1% 10.5M/1.72G [00:00<00:26, 63.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)tokenizer/vocab.json: 100% 1.06M/1.06M [00:00<00:00, 5.76MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)tokenizer/vocab.json: 100% 1.06M/1.06M [00:00<00:00, 5.27MB/s]\n",
            "\n",
            "Downloading (…)\"pytorch_model.bin\";:  10% 62.9M/608M [00:00<00:06, 89.2MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)\"pytorch_model.bin\";:  21% 52.4M/246M [00:00<00:02, 74.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:   1% 21.0M/1.72G [00:00<00:29, 57.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:  13% 21.0M/167M [00:00<00:02, 57.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)\"pytorch_model.bin\";:  26% 62.9M/246M [00:00<00:02, 70.0MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)\"pytorch_model.bin\";:  12% 73.4M/608M [00:00<00:07, 76.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:  19% 31.5M/167M [00:00<00:01, 68.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:   2% 41.9M/1.72G [00:00<00:19, 84.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)\"pytorch_model.bin\";:  30% 73.4M/246M [00:01<00:02, 71.8MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)\"pytorch_model.bin\";:  14% 83.9M/608M [00:01<00:07, 72.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:  25% 41.9M/167M [00:00<00:01, 65.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)\"pytorch_model.bin\";:  34% 83.9M/246M [00:01<00:02, 64.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:   3% 52.4M/1.72G [00:00<00:24, 68.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)\"pytorch_model.bin\";:  16% 94.4M/608M [00:01<00:07, 68.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:  31% 52.4M/167M [00:00<00:01, 73.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)\"pytorch_model.bin\";:  17% 105M/608M [00:01<00:06, 75.6MB/s] \u001b[A\n",
            "\n",
            "Downloading (…)\"pytorch_model.bin\";:  38% 94.4M/246M [00:01<00:02, 68.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:   4% 62.9M/1.72G [00:00<00:22, 72.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:  38% 62.9M/167M [00:00<00:01, 80.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)\"pytorch_model.bin\";:  19% 115M/608M [00:01<00:06, 73.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:   4% 73.4M/1.72G [00:01<00:23, 68.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)\"pytorch_model.bin\";:  43% 105M/246M [00:01<00:02, 64.6MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:  44% 73.4M/167M [00:01<00:01, 68.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)\"pytorch_model.bin\";:  21% 126M/608M [00:01<00:06, 73.5MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)\"pytorch_model.bin\";:  47% 115M/246M [00:01<00:01, 70.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:   5% 83.9M/1.72G [00:01<00:23, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)\"pytorch_model.bin\";:  22% 136M/608M [00:01<00:05, 79.9MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)\"pytorch_model.bin\";:  51% 126M/246M [00:01<00:01, 68.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:   5% 94.4M/1.72G [00:01<00:24, 67.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:  56% 94.4M/167M [00:01<00:00, 74.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)\"pytorch_model.bin\";:  24% 147M/608M [00:01<00:06, 67.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:   6% 105M/1.72G [00:01<00:22, 71.5MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:  63% 105M/167M [00:01<00:00, 71.2MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)\"pytorch_model.bin\";:  55% 136M/246M [00:02<00:01, 63.5MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)\"pytorch_model.bin\";:  26% 157M/608M [00:02<00:06, 69.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:   7% 115M/1.72G [00:01<00:21, 73.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:  69% 115M/167M [00:01<00:00, 70.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)\"pytorch_model.bin\";:  60% 147M/246M [00:02<00:01, 65.6MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)\"pytorch_model.bin\";:  28% 168M/608M [00:02<00:06, 69.2MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)\"pytorch_model.bin\";:  64% 157M/246M [00:02<00:01, 71.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:   7% 126M/1.72G [00:01<00:23, 69.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:  75% 126M/167M [00:01<00:00, 73.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)\"pytorch_model.bin\";:  29% 178M/608M [00:02<00:05, 74.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:  81% 136M/167M [00:01<00:00, 78.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:   8% 136M/1.72G [00:01<00:21, 72.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)\"pytorch_model.bin\";:  68% 168M/246M [00:02<00:01, 72.0MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)\"pytorch_model.bin\";:  31% 189M/608M [00:02<00:05, 77.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:   9% 147M/1.72G [00:02<00:23, 68.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)\"pytorch_model.bin\";:  33% 199M/608M [00:02<00:05, 77.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:  88% 147M/167M [00:02<00:00, 66.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)\"pytorch_model.bin\";:  72% 178M/246M [00:02<00:01, 61.5MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)\"pytorch_model.bin\";:  34% 210M/608M [00:02<00:04, 82.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:  94% 157M/167M [00:02<00:00, 72.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:   9% 157M/1.72G [00:02<00:22, 68.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)\"pytorch_model.bin\";:  77% 189M/246M [00:02<00:00, 64.6MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)\"pytorch_model.bin\";:  36% 220M/608M [00:02<00:04, 86.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:  10% 168M/1.72G [00:02<00:23, 67.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)\"pytorch_model.bin\";:  81% 199M/246M [00:02<00:00, 70.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";: 100% 167M/167M [00:02<00:00, 65.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)_pytorch_model.bin\";: 100% 167M/167M [00:02<00:00, 67.8MB/s]\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:  10% 178M/1.72G [00:02<00:22, 70.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)\"pytorch_model.bin\";:  85% 210M/246M [00:03<00:00, 70.6MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)\"pytorch_model.bin\";:  40% 241M/608M [00:03<00:04, 88.5MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)\"pytorch_model.bin\";:  89% 220M/246M [00:03<00:00, 76.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:  12% 199M/1.72G [00:02<00:18, 84.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)\"pytorch_model.bin\";:  43% 262M/608M [00:03<00:03, 101MB/s] \u001b[A\n",
            "\n",
            "Downloading (…)\"pytorch_model.bin\";:  94% 231M/246M [00:03<00:00, 82.6MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)\"pytorch_model.bin\";:  45% 273M/608M [00:03<00:03, 102MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)\"pytorch_model.bin\";:  98% 241M/246M [00:03<00:00, 87.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)\"pytorch_model.bin\";: 100% 246M/246M [00:03<00:00, 70.3MB/s]\n",
            "\n",
            "Downloading (…)\"pytorch_model.bin\";:  48% 294M/608M [00:03<00:02, 106MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:  14% 241M/1.72G [00:03<00:14, 102MB/s] \u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)\"pytorch_model.bin\";:  52% 315M/608M [00:03<00:02, 120MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:  15% 262M/1.72G [00:03<00:12, 118MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)\"pytorch_model.bin\";:  55% 336M/608M [00:03<00:02, 110MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:  16% 283M/1.72G [00:03<00:12, 112MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)\"pytorch_model.bin\";:  59% 357M/608M [00:04<00:02, 106MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:  18% 304M/1.72G [00:03<00:13, 107MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)\"pytorch_model.bin\";:  62% 377M/608M [00:04<00:02, 104MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:  19% 325M/1.72G [00:03<00:12, 108MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)\"pytorch_model.bin\";:  66% 398M/608M [00:04<00:01, 109MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:  20% 346M/1.72G [00:04<00:12, 111MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)\"pytorch_model.bin\";:  69% 419M/608M [00:04<00:01, 111MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:  21% 367M/1.72G [00:04<00:12, 109MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)\"pytorch_model.bin\";:  72% 440M/608M [00:04<00:01, 113MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:  23% 388M/1.72G [00:04<00:11, 117MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)\"pytorch_model.bin\";:  76% 461M/608M [00:05<00:01, 122MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:  24% 409M/1.72G [00:04<00:10, 120MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)\"pytorch_model.bin\";:  79% 482M/608M [00:05<00:01, 124MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:  25% 430M/1.72G [00:04<00:11, 114MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)\"pytorch_model.bin\";:  83% 503M/608M [00:05<00:00, 118MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:  26% 451M/1.72G [00:04<00:10, 120MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)\"pytorch_model.bin\";:  86% 524M/608M [00:05<00:00, 122MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:  27% 472M/1.72G [00:05<00:09, 127MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)\"pytorch_model.bin\";:  90% 545M/608M [00:05<00:00, 121MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:  29% 493M/1.72G [00:05<00:10, 121MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)\"pytorch_model.bin\";:  93% 566M/608M [00:05<00:00, 119MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:  30% 514M/1.72G [00:05<00:10, 119MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)\"pytorch_model.bin\";:  97% 587M/608M [00:06<00:00, 115MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:  31% 535M/1.72G [00:05<00:10, 109MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)\"pytorch_model.bin\";: 100% 608M/608M [00:06<00:00, 97.8MB/s]\n",
            "Fetching 15 files:  27% 4/15 [00:06<00:19,  1.74s/it]\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:  32% 556M/1.72G [00:05<00:10, 112MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:  34% 577M/1.72G [00:06<00:10, 107MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:  35% 598M/1.72G [00:06<00:09, 120MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:  36% 619M/1.72G [00:06<00:08, 137MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:  38% 650M/1.72G [00:06<00:06, 159MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:  39% 671M/1.72G [00:06<00:06, 160MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:  40% 692M/1.72G [00:06<00:06, 162MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:  42% 724M/1.72G [00:06<00:06, 161MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:  44% 755M/1.72G [00:07<00:05, 172MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:  45% 776M/1.72G [00:07<00:05, 175MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:  46% 797M/1.72G [00:07<00:06, 138MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:  48% 818M/1.72G [00:07<00:06, 147MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:  49% 839M/1.72G [00:07<00:05, 157MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:  50% 860M/1.72G [00:07<00:05, 165MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:  52% 891M/1.72G [00:07<00:04, 178MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:  54% 923M/1.72G [00:08<00:04, 184MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:  55% 954M/1.72G [00:08<00:03, 193MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:  57% 975M/1.72G [00:08<00:03, 194MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:  58% 996M/1.72G [00:08<00:03, 195MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:  59% 1.02G/1.72G [00:08<00:03, 198MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:  60% 1.04G/1.72G [00:08<00:04, 161MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:  62% 1.06G/1.72G [00:08<00:03, 171MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:  63% 1.08G/1.72G [00:08<00:03, 181MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:  64% 1.10G/1.72G [00:08<00:03, 184MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:  66% 1.13G/1.72G [00:09<00:03, 181MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:  67% 1.15G/1.72G [00:09<00:03, 188MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:  69% 1.18G/1.72G [00:09<00:02, 197MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:  70% 1.21G/1.72G [00:09<00:02, 197MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:  71% 1.23G/1.72G [00:09<00:02, 196MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:  73% 1.25G/1.72G [00:09<00:02, 193MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:  74% 1.27G/1.72G [00:09<00:03, 142MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:  76% 1.30G/1.72G [00:10<00:02, 159MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:  77% 1.32G/1.72G [00:10<00:02, 167MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:  78% 1.34G/1.72G [00:10<00:02, 177MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:  79% 1.36G/1.72G [00:10<00:01, 185MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:  81% 1.38G/1.72G [00:10<00:01, 175MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:  82% 1.41G/1.72G [00:10<00:01, 176MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:  84% 1.44G/1.72G [00:10<00:01, 189MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:  85% 1.47G/1.72G [00:11<00:01, 197MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:  87% 1.49G/1.72G [00:11<00:01, 186MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:  88% 1.51G/1.72G [00:11<00:01, 145MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:  90% 1.54G/1.72G [00:11<00:01, 165MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:  91% 1.56G/1.72G [00:11<00:00, 168MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:  93% 1.59G/1.72G [00:11<00:00, 182MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:  94% 1.61G/1.72G [00:11<00:00, 187MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:  95% 1.64G/1.72G [00:11<00:00, 191MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:  96% 1.66G/1.72G [00:12<00:00, 192MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";:  98% 1.69G/1.72G [00:12<00:00, 193MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)_pytorch_model.bin\";: 100% 1.72G/1.72G [00:12<00:00, 138MB/s]\n",
            "Fetching 15 files: 100% 15/15 [00:13<00:00,  1.13it/s]\n",
            " * Serving Flask app 'main'\n",
            " * Debug mode: off\n",
            "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            " * Running on http://5e79-146-148-40-197.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n",
            "127.0.0.1 - - [02/Mar/2023 13:45:18] \"GET / HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [02/Mar/2023 13:45:18] \"GET /static/styles.css HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [02/Mar/2023 13:45:19] \"GET /static/js/main.js HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [02/Mar/2023 13:45:21] \"GET /static/icon.png HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [02/Mar/2023 13:45:24] \"\u001b[36mGET /static/styles.css HTTP/1.1\u001b[0m\" 304 -\n",
            "127.0.0.1 - - [02/Mar/2023 13:45:31] \"GET / HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [02/Mar/2023 13:45:31] \"\u001b[36mGET /static/styles.css HTTP/1.1\u001b[0m\" 304 -\n",
            "127.0.0.1 - - [02/Mar/2023 13:45:32] \"\u001b[36mGET /static/js/main.js HTTP/1.1\u001b[0m\" 304 -\n",
            "127.0.0.1 - - [02/Mar/2023 13:45:32] \"\u001b[36mGET /static/icon.png HTTP/1.1\u001b[0m\" 304 -\n",
            "127.0.0.1 - - [02/Mar/2023 13:45:35] \"GET / HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [02/Mar/2023 13:45:35] \"\u001b[36mGET /static/styles.css HTTP/1.1\u001b[0m\" 304 -\n",
            "127.0.0.1 - - [02/Mar/2023 13:45:35] \"GET /static/js/jquery-3.6.3.min.js HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [02/Mar/2023 13:45:35] \"\u001b[36mGET /static/js/main.js HTTP/1.1\u001b[0m\" 304 -\n",
            "127.0.0.1 - - [02/Mar/2023 13:45:36] \"\u001b[36mGET /static/icon.png HTTP/1.1\u001b[0m\" 304 -\n",
            "100% 50/50 [00:12<00:00,  3.92it/s]\n",
            "Sending image ...\n",
            "127.0.0.1 - - [02/Mar/2023 13:46:28] \"POST /submit-prompt HTTP/1.1\" 200 -\n",
            "100% 50/50 [00:09<00:00,  5.43it/s]\n",
            "Sending image ...\n",
            "127.0.0.1 - - [02/Mar/2023 13:47:01] \"POST /submit-prompt HTTP/1.1\" 200 -\n",
            "100% 50/50 [00:09<00:00,  5.43it/s]\n",
            "Sending image ...\n",
            "127.0.0.1 - - [02/Mar/2023 13:47:34] \"POST /submit-prompt HTTP/1.1\" 200 -\n",
            "100% 50/50 [00:09<00:00,  5.39it/s]\n",
            "Sending image ...\n",
            "127.0.0.1 - - [02/Mar/2023 13:48:13] \"POST /submit-prompt HTTP/1.1\" 200 -\n",
            "100% 50/50 [00:09<00:00,  5.30it/s]\n",
            "Sending image ...\n",
            "127.0.0.1 - - [02/Mar/2023 13:51:03] \"POST /submit-prompt HTTP/1.1\" 200 -\n",
            "100% 50/50 [00:09<00:00,  5.21it/s]\n",
            "Sending image ...\n",
            "127.0.0.1 - - [02/Mar/2023 13:51:32] \"POST /submit-prompt HTTP/1.1\" 200 -\n",
            "100% 50/50 [00:09<00:00,  5.01it/s]\n",
            "Sending image ...\n",
            "127.0.0.1 - - [02/Mar/2023 13:52:03] \"POST /submit-prompt HTTP/1.1\" 200 -\n",
            "100% 50/50 [00:10<00:00,  4.93it/s]\n",
            "Sending image ...\n",
            "127.0.0.1 - - [02/Mar/2023 13:52:31] \"POST /submit-prompt HTTP/1.1\" 200 -\n",
            "100% 50/50 [00:10<00:00,  4.83it/s]\n",
            "Sending image ...\n",
            "127.0.0.1 - - [02/Mar/2023 13:53:04] \"POST /submit-prompt HTTP/1.1\" 200 -\n",
            "100% 50/50 [00:10<00:00,  4.60it/s]\n",
            "Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.\n",
            "Sending image ...\n",
            "127.0.0.1 - - [02/Mar/2023 13:54:06] \"POST /submit-prompt HTTP/1.1\" 200 -\n",
            "100% 50/50 [00:11<00:00,  4.48it/s]\n",
            "Sending image ...\n",
            "127.0.0.1 - - [02/Mar/2023 13:54:37] \"POST /submit-prompt HTTP/1.1\" 200 -\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['hrbacher and dawid planet']\n",
            "100% 50/50 [00:11<00:00,  4.52it/s]\n",
            "Sending image ...\n",
            "127.0.0.1 - - [02/Mar/2023 13:55:58] \"POST /submit-prompt HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [02/Mar/2023 13:56:25] \"GET / HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [02/Mar/2023 13:56:26] \"\u001b[36mGET /static/styles.css HTTP/1.1\u001b[0m\" 304 -\n",
            "127.0.0.1 - - [02/Mar/2023 13:56:26] \"\u001b[36mGET /static/js/jquery-3.6.3.min.js HTTP/1.1\u001b[0m\" 304 -\n",
            "127.0.0.1 - - [02/Mar/2023 13:56:26] \"\u001b[36mGET /static/js/main.js HTTP/1.1\u001b[0m\" 304 -\n",
            "127.0.0.1 - - [02/Mar/2023 13:56:27] \"\u001b[36mGET /static/icon.png HTTP/1.1\u001b[0m\" 304 -\n",
            "100% 50/50 [00:11<00:00,  4.27it/s]\n",
            "Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.\n",
            "Sending image ...\n",
            "127.0.0.1 - - [02/Mar/2023 13:58:30] \"POST /submit-prompt HTTP/1.1\" 200 -\n",
            "100% 50/50 [00:10<00:00,  4.66it/s]\n",
            "Sending image ...\n",
            "127.0.0.1 - - [02/Mar/2023 13:58:57] \"POST /submit-prompt HTTP/1.1\" 200 -\n",
            "100% 50/50 [00:10<00:00,  4.64it/s]\n",
            "Sending image ...\n",
            "127.0.0.1 - - [02/Mar/2023 13:59:29] \"POST /submit-prompt HTTP/1.1\" 200 -\n",
            "100% 50/50 [00:11<00:00,  4.40it/s]\n",
            "Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.\n",
            "Sending image ...\n",
            "127.0.0.1 - - [02/Mar/2023 14:00:32] \"POST /submit-prompt HTTP/1.1\" 200 -\n",
            "100% 50/50 [00:11<00:00,  4.46it/s]\n",
            "Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.\n",
            "Sending image ...\n",
            "127.0.0.1 - - [02/Mar/2023 14:00:51] \"POST /submit-prompt HTTP/1.1\" 200 -\n",
            "100% 50/50 [00:10<00:00,  4.73it/s]\n",
            "Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.\n",
            "Sending image ...\n",
            "127.0.0.1 - - [02/Mar/2023 14:01:22] \"POST /submit-prompt HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [02/Mar/2023 14:01:25] \"GET / HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [02/Mar/2023 14:01:26] \"\u001b[36mGET /static/styles.css HTTP/1.1\u001b[0m\" 304 -\n",
            "127.0.0.1 - - [02/Mar/2023 14:01:26] \"\u001b[36mGET /static/js/jquery-3.6.3.min.js HTTP/1.1\u001b[0m\" 304 -\n",
            "127.0.0.1 - - [02/Mar/2023 14:01:26] \"\u001b[36mGET /static/js/main.js HTTP/1.1\u001b[0m\" 304 -\n",
            "127.0.0.1 - - [02/Mar/2023 14:01:27] \"\u001b[36mGET /static/icon.png HTTP/1.1\u001b[0m\" 304 -\n",
            "100% 50/50 [00:11<00:00,  4.50it/s]\n",
            "Sending image ...\n",
            "127.0.0.1 - - [02/Mar/2023 14:02:00] \"POST /submit-prompt HTTP/1.1\" 200 -\n",
            "100% 50/50 [00:10<00:00,  4.57it/s]\n",
            "Sending image ...\n",
            "127.0.0.1 - - [02/Mar/2023 14:02:38] \"POST /submit-prompt HTTP/1.1\" 200 -\n",
            "Exception ignored in: <module 'threading' from '/usr/lib/python3.8/threading.py'>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.8/threading.py\", line 1355, in _shutdown\n",
            "    def _shutdown():\n",
            "KeyboardInterrupt: \n"
          ]
        }
      ],
      "source": [
        "!python main.py"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
